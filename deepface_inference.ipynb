{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e695d75-3825-4b89-ab92-899049a79f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepface.detectors import SsdWrapper\n",
    "from deepface.detectors import OpenCvWrapper\n",
    "from deepface.commons import distance as dst\n",
    "from deepface.commons import functions\n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(detector, img):\n",
    "\n",
    "    detected_face = None\n",
    "    img_region = None\n",
    "    img_region = [0, 0, img.shape[1], img.shape[0]]\n",
    "\n",
    "    ssd_labels = [\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"]\n",
    "\n",
    "    target_size = (300, 300)\n",
    "\n",
    "    base_img = img.copy()  # we will restore base_img to img later\n",
    "\n",
    "    original_size = img.shape\n",
    "\n",
    "    img = cv2.resize(img, target_size)\n",
    "\n",
    "    aspect_ratio_x = original_size[1] / target_size[1]\n",
    "    aspect_ratio_y = original_size[0] / target_size[0]\n",
    "\n",
    "    imageBlob = cv2.dnn.blobFromImage(image=img)\n",
    "\n",
    "    face_detector = detector[\"face_detector\"]\n",
    "    face_detector.setInput(imageBlob)\n",
    "    detections = face_detector.forward()\n",
    "\n",
    "    detections_df = pd.DataFrame(detections[0][0], columns=ssd_labels)\n",
    "\n",
    "    detections_df = detections_df[detections_df[\"is_face\"] == 1]  # 0: background, 1: face\n",
    "    detections_df = detections_df[detections_df[\"confidence\"] >= 0.90]\n",
    "\n",
    "    detections_df[\"left\"] = (detections_df[\"left\"] * 300).astype(int)\n",
    "    detections_df[\"bottom\"] = (detections_df[\"bottom\"] * 300).astype(int)\n",
    "    detections_df[\"right\"] = (detections_df[\"right\"] * 300).astype(int)\n",
    "    detections_df[\"top\"] = (detections_df[\"top\"] * 300).astype(int)\n",
    "\n",
    "    for _, instance in detections_df.iterrows():\n",
    "\n",
    "        left = instance[\"left\"]\n",
    "        right = instance[\"right\"]\n",
    "        bottom = instance[\"bottom\"]\n",
    "        top = instance[\"top\"]\n",
    "\n",
    "        detected_face = base_img[\n",
    "            int(top * aspect_ratio_y) : int(bottom * aspect_ratio_y),\n",
    "            int(left * aspect_ratio_x) : int(right * aspect_ratio_x),\n",
    "        ]\n",
    "        img_region = [\n",
    "            int(left * aspect_ratio_x),\n",
    "            int(top * aspect_ratio_y),\n",
    "            int(right * aspect_ratio_x) - int(left * aspect_ratio_x),\n",
    "            int(bottom * aspect_ratio_y) - int(top * aspect_ratio_y),\n",
    "        ]\n",
    "        if 0 in detected_face.shape:\n",
    "            return [None, None]\n",
    "        \n",
    "        detected_face = OpenCvWrapper.align_face(detector[\"eye_detector\"], detected_face)\n",
    "        break\n",
    "\n",
    "    return [detected_face, img_region]\n",
    "\n",
    "\n",
    "def extract_faces(img, target_size):\n",
    "    current_img, current_region = detect_face(SsdWrapper.build_model(), img)\n",
    "    if current_img is not None:\n",
    "\n",
    "        # resize and padding\n",
    "        if current_img.shape[0] > 0 and current_img.shape[1] > 0:\n",
    "            factor_0 = target_size[0] / current_img.shape[0]\n",
    "            factor_1 = target_size[1] / current_img.shape[1]\n",
    "            factor = min(factor_0, factor_1)\n",
    "\n",
    "            dsize = (int(current_img.shape[1] * factor), int(current_img.shape[0] * factor))\n",
    "            current_img = cv2.resize(current_img, dsize)\n",
    "\n",
    "            diff_0 = target_size[0] - current_img.shape[0]\n",
    "            diff_1 = target_size[1] - current_img.shape[1]\n",
    "            \n",
    "            current_img = np.pad(\n",
    "                current_img,\n",
    "                (\n",
    "                    (diff_0 // 2, diff_0 - diff_0 // 2),\n",
    "                    (diff_1 // 2, diff_1 - diff_1 // 2),\n",
    "                    (0, 0),\n",
    "                ),\n",
    "                \"constant\",\n",
    "            )\n",
    "\n",
    "        # double check: if target image is not still the same size with target.\n",
    "        if current_img.shape[0:2] != target_size:\n",
    "            current_img = cv2.resize(current_img, target_size)\n",
    "\n",
    "        # normalizing the image pixels\n",
    "        current_img = image.img_to_array(current_img)  # what this line doing? must?\n",
    "        current_img = np.expand_dims(current_img, axis=0)\n",
    "        current_img /= 255  # normalize input in [0, 1]\n",
    "\n",
    "    return [current_img, current_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste database path like: \"C:/workspace/my_db\"\n",
    "db_path = \"\"\n",
    "model_name=\"Facenet512\"\n",
    "detector_backend=\"ssd\"\n",
    "distance_metric=\"cosine\"\n",
    "source=0\n",
    "target_size = functions.find_target_size(model_name=model_name)\n",
    "\n",
    "# ------------------------\n",
    "model = DeepFace.build_model(model_name=model_name)\n",
    "print(f\"facial recognition model {model_name} is just built\")\n",
    "\n",
    "DeepFace.find(\n",
    "    img_path=np.zeros([400, 400, 3], dtype='uint8'),\n",
    "    db_path=db_path,\n",
    "    model_name=model_name,\n",
    "    detector_backend=detector_backend,\n",
    "    distance_metric=distance_metric,\n",
    "    enforce_detection=False,\n",
    ")\n",
    "# -----------------------\n",
    "\n",
    "file_name = f\"representations_{model_name}.pkl\"\n",
    "file_name = file_name.replace(\"-\", \"_\").lower()\n",
    "\n",
    "with open(f\"{db_path}/{file_name}\", \"rb\") as f:\n",
    "    representations = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(representations, columns=[\"identity\", f\"{model_name}_representation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(source)  # webcam\n",
    "while True:\n",
    "    tic = time.time()\n",
    "\n",
    "    _, img = cap.read()\n",
    "    if img is None:\n",
    "        break\n",
    "\n",
    "    raw_img = img.copy()\n",
    "    target_img, target_region = extract_faces(raw_img, target_size)\n",
    "\n",
    "    if target_img is not None:\n",
    "        x, y, w, h = target_region\n",
    "\n",
    "        if w > 130:  # discard small detected faces\n",
    "\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 200, 200), 5)\n",
    "\n",
    "            target_representation = model(target_img, training=False).numpy()[0].tolist()\n",
    "            result_df = df.copy()  # df will be filtered in each img\n",
    "\n",
    "            distances = []\n",
    "            for index, instance in df.iterrows():\n",
    "                source_representation = instance[f\"{model_name}_representation\"]\n",
    "\n",
    "                if distance_metric == \"cosine\":\n",
    "                    distance = dst.findCosineDistance(source_representation, target_representation)\n",
    "                elif distance_metric == \"euclidean\":\n",
    "                    distance = dst.findEuclideanDistance(source_representation, target_representation)\n",
    "                elif distance_metric == \"euclidean_l2\":\n",
    "                    distance = dst.findEuclideanDistance(\n",
    "                        dst.l2_normalize(source_representation),\n",
    "                        dst.l2_normalize(target_representation),\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f\"invalid distance metric passes - {distance_metric}\")\n",
    "\n",
    "                distances.append(distance)\n",
    "\n",
    "                # ---------------------------\n",
    "\n",
    "            result_df[f\"{model_name}_{distance_metric}\"] = distances\n",
    "\n",
    "            threshold = dst.findThreshold(model_name, distance_metric)\n",
    "            result_df = result_df[result_df[f\"{model_name}_{distance_metric}\"] <= threshold]\n",
    "            result_df = result_df.sort_values(\n",
    "                by=[f\"{model_name}_{distance_metric}\"], ascending=True\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            if result_df.shape[0] > 0:\n",
    "                label = result_df.loc[0, \"identity\"].split(\"/\")[-1]\n",
    "                img = cv2.putText(img, label.split('.')[0], (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                # -------------------------------\n",
    "\n",
    "    toc = time.time()\n",
    "\n",
    "    img = cv2.putText(img, str(round(1/(toc-tic), 1)), (img.shape[1]-70,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"img\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # press q to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
